{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "x = [[1,2,3],   #x는 학습용, y는 정답\n",
    "    [11, 12, 13]]\n",
    "y = [0,1]\n",
    "clf.fit(x, y) #학습시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(x)  # 예측한 데이터를 다시 넣음, 이런짓하지 말자...ㅜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[4,5,6],[14,15,16]])  # 일반적으로 데이터는 전체데이터를 7:3의 비율로 학습데이터와 테스트 데이터로 나눠서 진행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score  #정확도 측정 모듈\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "==================================================\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] <class 'list'>\n",
      "==================================================\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]] <class 'numpy.ndarray'>\n",
      "==================================================\n",
      "['setosa' 'versicolor' 'virginica'] <class 'numpy.ndarray'>\n",
      "==================================================\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "iris_data =load_iris()\n",
    "print(iris_data.keys())\n",
    "print('='*50)\n",
    "print(iris_data.feature_names, type(iris_data.feature_names)) # 컬럼명\n",
    "print('='*50)\n",
    "print(iris_data.data, type(iris_data.data))                   #학습데이터 실제 값\n",
    "print('='*50)\n",
    "print(iris_data.target_names, type(iris_data.target_names))  #컬럼명\n",
    "print('='*50)\n",
    "print(iris_data.target, type(iris_data.target))              #정답 레이블 실제 값\n",
    "df = pd.DataFrame(data=iris_data.data, columns=iris_data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 4.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)  \n",
       "count        150.000000  \n",
       "mean           1.199333  \n",
       "std            0.762238  \n",
       "min            0.100000  \n",
       "25%            0.300000  \n",
       "50%            1.300000  \n",
       "75%            1.800000  \n",
       "max            2.500000  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()  #대략적인 데이터 분포도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(iris_data.target).value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=11) \n",
    " # 문제용 (훈련, 학습), 정답용(훈련, 학습)\n",
    "#훈련용과 테스트용 데이터 분리 (7:3)\n",
    "\n",
    "\n",
    "train_data = iris_data.data\n",
    "target_data = iris_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111\n"
     ]
    }
   ],
   "source": [
    "dt_model.fit(x_train, y_train)  #해당 모델로 훈련, 학습완료\n",
    "dt_model_pred = dt_model.predict(x_test) # 문제로 시험보기 (D.T 알고리즘이 정답을 제출함)\n",
    "score = accuracy_score(y_test, dt_model_pred) # 모델이 낸 답안지와 데스트용 답안지 비교 : 정확도 확인\n",
    "print(round(score, 4))  #91% 정확도 도출 \n",
    "#정확도가 너무 높은 경우, 과대적합(OverFitting)의 문제가 발생했다고 볼 수 있다. 혹은 데이터양이 너무 작아 정확도를 신뢰하기 어렵다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation (K겹 교차 검증)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "from inspect import signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (n_splits=5, *, shuffle=False, random_state=None)>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = load_iris()  #데이터 변경가능성 있어 온전한 데이터로 다시 불러온다. \n",
    "\n",
    "kfold = KFold(n_splits=5) #데이터를 5등분한다. 즉 150개 레코드를 30개씩 묶는다. \n",
    "signature(KFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for idx_train, idx_test in kfold.split(iris_data):\n",
    "    x_train, x_test = iris_data.data[idx_train], iris_data.data[idx_test]   \n",
    "    y_train, y_test = iris_data.target[idx_train], iris_data.target[idx_test]\n",
    "    \n",
    "    \n",
    "# KFold는 트레이닝 들어갈 인덱스와, 테스트용 인덱스 2개를 반환한다.     \n",
    "# 반환된 것을 훈련용과 테스트용으로 구분하여 담는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 \n",
      " 6 \n",
      " 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_model.fit(x_train, y_train)  \n",
    "dt_model_pred = dt_model.predict(x_test) \n",
    "score = accuracy_score(y_test, dt_model_pred)\n",
    "scores.append(score)\n",
    "print(round(score, 4),'\\n', x_train.shape[0], '\\n', x_test.shape[0], '\\n')\n",
    "# 이어서 학습하고 테스트해서 정확도를 검사한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "평균 accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "print('평균 accuracy : ', np.mean(scores))  \n",
    "# 평균 accuracy :  1.0  결과가 100% 정확도를 나타낸다. 이유를 살펴보면, 정답 데이터가 이미 0,1로 순서대로 정렬되어 있다. \n",
    "# 따라서, 이미 정리된 데이터(00000...11111)를 30개씩 나눠서 돌린 결과가 나온것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 작은 구성비를 가진 데이터들이 모두 Train 또는 Test데이터로 분리된 경우 제대로 학습과 테스트를 진행할 수가 없다.\n",
    "# 따라서, 구성 비가 다른 불균형 데이터를 다룰 때는 Stratified가 붙은 클래스를 이용하거나 stratify옵션을 켜야한다.\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "label\n",
      "2        50\n",
      "1        50\n",
      "0        50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "x_iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "y_iris_df = pd.DataFrame(data=iris.target, columns=['label'])  # 정답지 \n",
    "print(x_iris_df.shape)\n",
    "print(y_iris_df.value_counts())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "iris = load_iris()\n",
    "\n",
    "x_iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "y_iris_df = pd.DataFrame(data=iris.target, columns=['label']) \n",
    "\n",
    "\n",
    "kfold=KFold(n_splits=3)\n",
    "n_iter=0\n",
    "\n",
    "for train_index, test_index in kfold.split(iris_df):\n",
    "    n_iter+=1\n",
    "    label_train=y_iris_df['label'].iloc[train_index]\n",
    "    label_test=y_iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "skf=StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "\n",
    "for train_index, test_index in skf.split(x_iris_df, y_iris_df['label']):\n",
    "    n_iter+=1\n",
    "    label_train=y_iris_df['label'].iloc[train_index]\n",
    "    label_test=y_iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증: {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dt_clf=DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "skfold=StratifiedKFold(n_splits=3)\n",
    "n_iter=0\n",
    "cv_accuracy=[]\n",
    "\n",
    "for train_index, test_index in skfold.split(features, label):\n",
    "#     학습용, 검증용 데이터\n",
    "    X_train, X_test=features[train_index], features[test_index]\n",
    "    y_train, y_test=label[train_index], label[test_index]\n",
    "    \n",
    "#     학습 및 예측\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "    pred=dt_clf.predict(X_test)\n",
    "    \n",
    "    n_iter+=1\n",
    "    accuracy=np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size=X_train.shape[0]\n",
    "    test_size=X_test.shape[0]\n",
    "    print('\\n{0} 교차 검증 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.\n",
    "         format(n_iter, accuracy, train_size, test_size))\n",
    "    print('#{0} 검증 세트 인덱스: {1}'.format(n_iter, test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "    \n",
    "print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
    "print('## 평균 검증 정확도: ',np.mean(cv_accuracy))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "skfold = StratifiedKFold(n_splits = 3) \n",
    "\n",
    "scores = []\n",
    "for idx_train, idx_test in skfold.split(x_iris_df, y_iris_df):   \n",
    "#     x_train, x_test = iris_data.data[idx_train], iris_data.data[idx_test]   \n",
    "#     y_train, y_test = iris_data.target[idx_train], iris_data.target[idx_test]\n",
    "    y_train = y_iris_df['label'].iloc[idx_train]\n",
    "    y_test = y_iris_df['label'].iloc[idx_test]\n",
    "    print(x_train.value_count())\n",
    "    print(x_test.value_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98 0.94 1.  ]\n",
      "0.9733333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "iris = load_iris()\n",
    "\n",
    "x_iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "y_iris_df = pd.DataFrame(data=iris.target, columns=['label'])  # 정답지 \n",
    "\n",
    "scores = cross_val_score(dt_model, x_iris_df, y_iris_df, scoring='accuracy', cv=3)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터(Hyperparameter) 튜닝하기\n",
    "### sklearn.model_selection.GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = load_iris()\n",
    "x_iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "y_iris_df = pd.DataFrame(data=iris.target, columns=['label'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_iris_df, y_iris_df, test_size=0.3, random_state=11) \n",
    "dt_model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sklearn.tree.DecisionTreeClassifier 의 Parameters 선택 ==>>\n",
    "- max_depth\n",
    "- min_samples_split : 값이 작을수록 decision tree의 depth가 깊다 \n",
    "**주의> depth가 깊어질수록 과적합의 가능성이 커진다.\n",
    "\n",
    "제공되는 iris 데이터는 별도의 데이터 전처리 과정이 필요하지 않을 정도로 정제되어 있는 데이터이기 때문에 높은 정확도가 산출된다. \n",
    "그러나, 실무에서는 모델의 정확도가 90%대 나오면 주의해야한다. \n",
    "보통 70~80 정도에 나온다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid 넘겨줄 하이퍼 파라미터 설정 \n",
    "params = {'max_depth' : [1,3,5],\n",
    "         'min_samples_split':[1,2,3]}\n",
    "\n",
    "GCV = GridSearchCV(dt_model, param_grid=params, refit=True, cv=3, scoring=\"accuracy\")\n",
    "# refit을 True로 설정하였기 때문에, 가장 최적의 파라미터를 찾아 고정된다. \n",
    "\n",
    "\n",
    "# 참고>\n",
    "#class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html?highlight=gridsearchcv#sklearn.model_selection.GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(),\n",
      "             param_grid={'max_depth': [1, 3, 5],\n",
      "                         'min_samples_split': [1, 2, 3]},\n",
      "             scoring='accuracy')\n",
      "================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean_fit_time            9 non-null      float64\n",
      " 1   std_fit_time             9 non-null      float64\n",
      " 2   mean_score_time          9 non-null      float64\n",
      " 3   std_score_time           9 non-null      float64\n",
      " 4   param_max_depth          9 non-null      object \n",
      " 5   param_min_samples_split  9 non-null      object \n",
      " 6   params                   9 non-null      object \n",
      " 7   split0_test_score        6 non-null      float64\n",
      " 8   split1_test_score        6 non-null      float64\n",
      " 9   split2_test_score        6 non-null      float64\n",
      " 10  mean_test_score          6 non-null      float64\n",
      " 11  std_test_score           6 non-null      float64\n",
      " 12  rank_test_score          9 non-null      int32  \n",
      "dtypes: float64(9), int32(1), object(3)\n",
      "memory usage: 1.0+ KB\n",
      "None\n",
      "--------------------------------------------------------------------------------\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.003358      0.001901         0.000000        0.000000   \n",
      "1       0.001997      0.000002         0.000995        0.000001   \n",
      "2       0.002310      0.000445         0.001014        0.000025   \n",
      "3       0.002992      0.000005         0.000000        0.000000   \n",
      "4       0.002321      0.000455         0.001668        0.000461   \n",
      "\n",
      "  param_max_depth param_min_samples_split  \\\n",
      "0               1                       1   \n",
      "1               1                       2   \n",
      "2               1                       3   \n",
      "3               3                       1   \n",
      "4               3                       2   \n",
      "\n",
      "                                     params  split0_test_score  \\\n",
      "0  {'max_depth': 1, 'min_samples_split': 1}                NaN   \n",
      "1  {'max_depth': 1, 'min_samples_split': 2}           0.685714   \n",
      "2  {'max_depth': 1, 'min_samples_split': 3}           0.685714   \n",
      "3  {'max_depth': 3, 'min_samples_split': 1}                NaN   \n",
      "4  {'max_depth': 3, 'min_samples_split': 2}           0.971429   \n",
      "\n",
      "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0                NaN                NaN              NaN             NaN   \n",
      "1           0.685714           0.685714         0.685714    1.110223e-16   \n",
      "2           0.685714           0.685714         0.685714    1.110223e-16   \n",
      "3                NaN                NaN              NaN             NaN   \n",
      "4           0.971429           0.971429         0.971429    0.000000e+00   \n",
      "\n",
      "   rank_test_score  \n",
      "0                7  \n",
      "1                5  \n",
      "2                5  \n",
      "3                8  \n",
      "4                1  \n",
      "================================================================================\n",
      "0.9714285714285714\n"
     ]
    }
   ],
   "source": [
    "GCV.fit(x_train, y_train)  # 학습완료 \n",
    "\n",
    "\n",
    "print(GCV)  # GCV 가 하나의 모델이 되어 있음. \n",
    "print('='*80)\n",
    "# print(GCV.cv_results_)\n",
    "df= pd.DataFrame(data= GCV.cv_results_)\n",
    "print(df.info())\n",
    "print('-'*80)\n",
    "print(df.head())\n",
    "print('='*80)\n",
    "print(GCV.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-367-7a6b03b98221>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGCV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbest_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mbest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\app\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    424\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m         \"\"\"\n\u001b[1;32m--> 426\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\app\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\app\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1020\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This DecisionTreeClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "best_model = GCV.best_estimator_\n",
    "best_pred = dt_model.predict(x_test)\n",
    "best_score = accuracy_score(y_test, best_pred)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9 entries, 0 to 8\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean_fit_time            9 non-null      float64\n",
      " 1   std_fit_time             9 non-null      float64\n",
      " 2   mean_score_time          9 non-null      float64\n",
      " 3   std_score_time           9 non-null      float64\n",
      " 4   param_max_depth          9 non-null      object \n",
      " 5   param_min_samples_split  9 non-null      object \n",
      " 6   params                   9 non-null      object \n",
      " 7   split0_test_score        6 non-null      float64\n",
      " 8   split1_test_score        6 non-null      float64\n",
      " 9   split2_test_score        6 non-null      float64\n",
      " 10  mean_test_score          6 non-null      float64\n",
      " 11  std_test_score           6 non-null      float64\n",
      " 12  rank_test_score          9 non-null      int32  \n",
      "dtypes: float64(9), int32(1), object(3)\n",
      "memory usage: 1.0+ KB\n",
      "None\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       0.002005      0.000015         0.000000        0.000000   \n",
      "1       0.002680      0.000464         0.001343        0.000483   \n",
      "2       0.002672      0.000431         0.000985        0.000011   \n",
      "3       0.002995      0.000056         0.000000        0.000000   \n",
      "4       0.002994      0.000005         0.000993        0.000004   \n",
      "\n",
      "  param_max_depth param_min_samples_split  \\\n",
      "0               1                       1   \n",
      "1               1                       2   \n",
      "2               1                       3   \n",
      "3               3                       1   \n",
      "4               3                       2   \n",
      "\n",
      "                                     params  split0_test_score  \\\n",
      "0  {'max_depth': 1, 'min_samples_split': 1}                NaN   \n",
      "1  {'max_depth': 1, 'min_samples_split': 2}           0.685714   \n",
      "2  {'max_depth': 1, 'min_samples_split': 3}           0.685714   \n",
      "3  {'max_depth': 3, 'min_samples_split': 1}                NaN   \n",
      "4  {'max_depth': 3, 'min_samples_split': 2}           0.971429   \n",
      "\n",
      "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
      "0                NaN                NaN              NaN             NaN   \n",
      "1           0.685714           0.685714         0.685714    1.110223e-16   \n",
      "2           0.685714           0.685714         0.685714    1.110223e-16   \n",
      "3                NaN                NaN              NaN             NaN   \n",
      "4           0.971429           0.971429         0.971429    0.000000e+00   \n",
      "\n",
      "   rank_test_score  \n",
      "0                7  \n",
      "1                5  \n",
      "2                5  \n",
      "3                8  \n",
      "4                1  \n",
      "{'max_depth': 3, 'min_samples_split': 2}\n",
      "0.9714285714285714\n",
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "iris_data = load_iris()\n",
    "X_iris_df = pd.DataFrame(data= iris_data.data, columns=iris_data.feature_names)\n",
    "y_iris_df = pd.DataFrame(data= iris_data.target, columns=[\"label\"])\n",
    "#하이퍼파라미터튜닝을 중점적으로(알고리즘의 속성값 튜닝)\n",
    "# min_samples_split:int or float, default = 2 default값이 클수록 뎁스가 얕은 것.\n",
    "#니들이 정해준대로 학습할테니 수치를 정해줘\n",
    "# dt_model = DecisionTreeClassifier()\n",
    "X_train,X_test,Y_train, Y_test =train_test_split(X_iris_df, y_iris_df, test_size = 0.3, random_state=11)\n",
    "dt_model = DecisionTreeClassifier()\n",
    "# print(X_train)\n",
    "# print(y_train)\n",
    "# max_depth\n",
    "# min_samples_splitint\n",
    "\n",
    "#pram_grid에 넘겨줄 하이퍼 파라미터\n",
    "params = {'max_depth' : [ 1,3,5],\n",
    "          'min_samples_split':[1,2,3]\n",
    "         }\n",
    "GCV = GridSearchCV(dt_model,param_grid=params,refit=True, cv=3, scoring='accuracy')\n",
    "GCV.fit(X_train, y_train) \n",
    "\n",
    "#학습완료,GCV안에 모든걸 다 가지고 있다. 다 따로 밖에서 score이 몇점인지 산술할 필요가 없다.\n",
    "# print(GCV.cv_results_)\n",
    "df = pd.DataFrame(data=GCV.cv_results_)\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "print(GCV.best_params_)\n",
    "print(GCV.best_score_)\n",
    "# 다음 명령을 사용하여 추가 차원을 np.array()정의 X하거나 나중에 추가 차원을 제거 할 때 추가 목록을 제거하십시오 \n",
    "# X = X.reshape(X.shape[1:]). 이제 모양은 X(6, 29)입니다.\n",
    "# 트랜스 X실행 X = X.transpose()의 샘플 같은 수를 얻을 수 X및 Y. 자, 모양X (29, 6)이고 모양은 Y(29,)입니다.\n",
    "\n",
    "##가장 좋은 형태\n",
    "# print(X_test)\n",
    "best_model = GCV.best_estimator_\n",
    "best_pred = best_model.predict(X_test)\n",
    "best_score = accuracy_score(y_test, best_pred)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_breast_cancer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-29e85a22daee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_breast_cancer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0miris_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#하이퍼파라미터튜닝을 중점적으로(알고리즘의 속성값 튜닝)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_breast_cancer' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "dataset = load_breast_cancer()\n",
    "X_df = pd.DataFrame(data= dataset .data, columns=iris_data.feature_names)\n",
    "y_df = pd.DataFrame(data= dataset.target, columns=[\"label\"])\n",
    "#하이퍼파라미터튜닝을 중점적으로(알고리즘의 속성값 튜닝)\n",
    "# min_samples_split:int or float, default = 2 default값이 클수록 뎁스가 얕은 것.\n",
    "#니들이 정해준대로 학습할테니 수치를 정해줘\n",
    "# dt_model = DecisionTreeClassifier()\n",
    "X_train,X_test,Y_train, Y_test =train_test_split(X_iris_df, y_iris_df, test_size = 0.3, random_state=11)\n",
    "dt_model = DecisionTreeClassifier()\n",
    "# print(X_train)\n",
    "# print(y_train)\n",
    "# max_depth\n",
    "# min_samples_splitint\n",
    "\n",
    "#pram_grid에 넘겨줄 하이퍼 파라미터\n",
    "params = {'max_depth' : [ 1,3,5],\n",
    "          'min_samples_split':[1,2,3]\n",
    "         }\n",
    "GCV = GridSearchCV(dt_model,param_grid=params,refit=True, cv=3, scoring='accuracy')\n",
    "GCV.fit(X_train, y_train) \n",
    "\n",
    "#학습완료,GCV안에 모든걸 다 가지고 있다. 다 따로 밖에서 score이 몇점인지 산술할 필요가 없다.\n",
    "# print(GCV.cv_results_)\n",
    "df = pd.DataFrame(data=GCV.cv_results_)\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "print(GCV.best_params_)\n",
    "print(GCV.best_score_)\n",
    "# 다음 명령을 사용하여 추가 차원을 np.array()정의 X하거나 나중에 추가 차원을 제거 할 때 추가 목록을 제거하십시오 \n",
    "# X = X.reshape(X.shape[1:]). 이제 모양은 X(6, 29)입니다.\n",
    "# 트랜스 X실행 X = X.transpose()의 샘플 같은 수를 얻을 수 X및 Y. 자, 모양X (29, 6)이고 모양은 Y(29,)입니다.\n",
    "\n",
    "##가장 좋은 형태\n",
    "# print(X_test)\n",
    "best_model = GCV.best_estimator_\n",
    "best_pred = best_model.predict(X_test)\n",
    "best_score = accuracy_score(y_test, best_pred)\n",
    "print(best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
